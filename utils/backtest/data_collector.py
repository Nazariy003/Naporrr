# utils/backtest/data_collector.py
import time
import asyncio
import pandas as pd
import pyarrow as pa
import pyarrow.parquet as pq
from pathlib import Path
from datetime import datetime, timedelta
from typing import Dict, List, Any
from config.settings import settings
from utils.logger import logger

class DataCollector:
    """
    üéØ –ó–±—ñ—Ä —ñ —Ä–æ—Ç–∞—Ü—ñ—è –¥–∞–Ω–∏—Ö –∑ –±—é–¥–∂–µ—Ç–æ–º 10 –ì–ë
    
    –†—ñ–≤–Ω—ñ –∑–±–µ—Ä—ñ–≥–∞–Ω–Ω—è:
    - RAW (7 –¥–Ω—ñ–≤): orderbook snapshots (5s) + trades + signals
    - AGGREGATED (30 –¥–Ω—ñ–≤): 1-min bars + aggregated signals
    - METADATA (90 –¥–Ω—ñ–≤): —Ç—ñ–ª—å–∫–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∏ —Å–∏–≥–Ω–∞–ª—ñ–≤
    """
    
    def __init__(self, storage_path: str = "utils/data_storage"):
        self.storage_path = Path(storage_path)
        self.raw_path = self.storage_path / "raw"
        self.agg_path = self.storage_path / "aggregated"
        self.meta_path = self.storage_path / "metadata"
        
        # –°—Ç–≤–æ—Ä–µ–Ω–Ω—è –¥–∏—Ä–µ–∫—Ç–æ—Ä—ñ–π
        for path in [self.raw_path, self.agg_path, self.meta_path]:
            path.mkdir(parents=True, exist_ok=True)
        
        # –ë—É—Ñ–µ—Ä–∏ –¥–ª—è –±–∞—Ç—á–æ–≤–æ–≥–æ –∑–∞–ø–∏—Å—É
        self.buffers = {
            'orderbook': {},
            'trades': {},
            'signals': {}
        }
        
        self.buffer_size = 100  # –ó–∞–ø–∏—Å—É—î–º–æ –∫–æ–∂–Ω—ñ 100 –∑–∞–ø–∏—Å—ñ–≤
        self.last_flush = time.time()
        
    async def start(self, storage, signal_generator):
        """–ó–∞–ø—É—Å–∫ –∑–±–æ—Ä—É –¥–∞–Ω–∏—Ö"""
        logger.info("üé¨ [DATA_COLLECTOR] Starting...")
        
        # –ü—ñ–¥–ø–∏—Å–∫–∞ –Ω–∞ –ø–æ–¥—ñ—ó
        storage.add_position_callback(self._on_position_update)
        
        # –¶–∏–∫–ª—ñ—á–Ω—ñ –∑–∞–¥–∞—á—ñ
        asyncio.create_task(self._snapshot_loop(storage))
        asyncio.create_task(self._trades_loop(storage))
        asyncio.create_task(self._signals_loop(signal_generator))
        asyncio.create_task(self._flush_loop())
        asyncio.create_task(self._rotation_loop())
        
        logger.info("‚úÖ [DATA_COLLECTOR] Started")
    
    async def _snapshot_loop(self, storage):
        """–ó–Ω—ñ–º–∫–∏ orderbook –∫–æ–∂–Ω—ñ 5 —Å–µ–∫—É–Ω–¥"""
        while True:
            try:
                await asyncio.sleep(5)
                
                for symbol in settings.pairs.trade_pairs:
                    ob = storage.get_order_book(symbol)
                    if not ob:
                        continue
                    
                    # –ó–±–µ—Ä—ñ–≥–∞—î–º–æ —Ç—ñ–ª—å–∫–∏ —Ç–æ–ø-10 —Ä—ñ–≤–Ω—ñ–≤ –¥–ª—è –µ–∫–æ–Ω–æ–º—ñ—ó –º—ñ—Å—Ü—è
                    snapshot = {
                        'timestamp': ob.ts,
                        'symbol': symbol,
                        'best_bid': ob.best_bid,
                        'best_ask': ob.best_ask,
                        'bid_levels': [(lvl.price, lvl.size) for lvl in ob.bids[:10]],
                        'ask_levels': [(lvl.price, lvl.size) for lvl in ob.asks[:10]],
                    }
                    
                    self._add_to_buffer('orderbook', symbol, snapshot)
                    
            except Exception as e:
                logger.error(f"‚ùå [SNAPSHOT_LOOP] Error: {e}")
    
    async def _trades_loop(self, storage):
        """–ó–±—ñ—Ä trades –∫–æ–∂–Ω—ñ 10 —Å–µ–∫—É–Ω–¥"""
        while True:
            try:
                await asyncio.sleep(10)
                
                for symbol in settings.pairs.trade_pairs:
                    trades = storage.get_trades(symbol)
                    if not trades:
                        continue
                    
                    for trade in trades:
                        trade_data = {
                            'timestamp': trade.ts,
                            'symbol': symbol,
                            'price': trade.price,
                            'size': trade.size,
                            'side': trade.side,
                            'is_aggressive': trade.is_aggressive
                        }
                        self._add_to_buffer('trades', symbol, trade_data)
                        
            except Exception as e:
                logger.error(f"‚ùå [TRADES_LOOP] Error: {e}")
    
    async def _signals_loop(self, signal_generator):
        """–ó–±—ñ—Ä —Å–∏–≥–Ω–∞–ª—ñ–≤ –∫–æ–∂–Ω—ñ 2 —Å–µ–∫—É–Ω–¥–∏"""
        while True:
            try:
                await asyncio.sleep(2)
                
                # –ó–±–µ—Ä—ñ–≥–∞—î–º–æ metadata —Å–∏–≥–Ω–∞–ª—ñ–≤ –¥–ª—è replay
                current_time = time.time()
                
                for symbol in settings.pairs.trade_pairs:
                    # –¢—É—Ç –º–∞—î –±—É—Ç–∏ –ª–æ–≥—ñ–∫–∞ –æ—Ç—Ä–∏–º–∞–Ω–Ω—è –ø–æ—Ç–æ—á–Ω–æ–≥–æ —Å–∏–≥–Ω–∞–ª—É
                    # –ù–∞—Ä–∞–∑—ñ placeholder
                    signal_data = {
                        'timestamp': current_time,
                        'symbol': symbol,
                        'signal': 'HOLD',  # BUY/SELL/HOLD
                        'strength': 0,
                        'composite': 0.0,
                        'imbalance': 0.0,
                        'momentum': 0.0,
                        'volatility': 0.0,
                        # –î–æ–¥–∞—Ç–∫–æ–≤—ñ –ø–∞—Ä–∞–º–µ—Ç—Ä–∏ –¥–ª—è replay
                        'settings_snapshot': {
                            'weight_imbalance': settings.signals.weight_imbalance,
                            'weight_momentum': settings.signals.weight_momentum,
                            'hold_threshold': settings.signals.hold_threshold,
                        }
                    }
                    self._add_to_buffer('signals', symbol, signal_data)
                    
            except Exception as e:
                logger.error(f"‚ùå [SIGNALS_LOOP] Error: {e}")
    
    def _add_to_buffer(self, buffer_type: str, symbol: str, data: Dict):
        """–î–æ–¥–∞–≤–∞–Ω–Ω—è –¥–æ –±—É—Ñ–µ—Ä–∞"""
        key = f"{symbol}_{buffer_type}"
        if key not in self.buffers[buffer_type]:
            self.buffers[buffer_type][key] = []
        
        self.buffers[buffer_type][key].append(data)
        
        # Flush —è–∫—â–æ –¥–æ—Å—è–≥–ª–∏ —Ä–æ–∑–º—ñ—Ä—É –±—É—Ñ–µ—Ä–∞
        if len(self.buffers[buffer_type][key]) >= self.buffer_size:
            self._flush_buffer(buffer_type, symbol)
    
    async def _flush_loop(self):
        """–ü–µ—Ä—ñ–æ–¥–∏—á–Ω–∏–π flush –±—É—Ñ–µ—Ä—ñ–≤ (–∫–æ–∂–Ω—ñ 60 —Å–µ–∫)"""
        while True:
            try:
                await asyncio.sleep(60)
                
                current_time = time.time()
                if current_time - self.last_flush >= 60:
                    self._flush_all_buffers()
                    self.last_flush = current_time
                    
            except Exception as e:
                logger.error(f"‚ùå [FLUSH_LOOP] Error: {e}")
    
    def _flush_buffer(self, buffer_type: str, symbol: str):
        """–ó–∞–ø–∏—Å –±—É—Ñ–µ—Ä–∞ –≤ Parquet"""
        key = f"{symbol}_{buffer_type}"
        
        if key not in self.buffers[buffer_type] or not self.buffers[buffer_type][key]:
            return
        
        try:
            # –ö–æ–Ω–≤–µ—Ä—Ç—É—î–º–æ –≤ DataFrame
            df = pd.DataFrame(self.buffers[buffer_type][key])
            
            # –®–ª—è—Ö –¥–æ —Ñ–∞–π–ª—É
            today = datetime.utcnow().strftime("%Y-%m-%d")
            file_path = self.raw_path / today / f"{symbol}_{buffer_type}.parquet"
            file_path.parent.mkdir(parents=True, exist_ok=True)
            
            # Append –¥–æ —ñ—Å–Ω—É—é—á–æ–≥–æ —Ñ–∞–π–ª—É –∞–±–æ —Å—Ç–≤–æ—Ä–µ–Ω–Ω—è –Ω–æ–≤–æ–≥–æ
            if file_path.exists():
                existing_df = pd.read_parquet(file_path)
                df = pd.concat([existing_df, df], ignore_index=True)
            
            # –ó–∞–ø–∏—Å –∑ –∫–æ–º–ø—Ä–µ—Å—ñ—î—é
            df.to_parquet(
                file_path,
                engine='pyarrow',
                compression='snappy',
                index=False
            )
            
            # –û—á–∏—â–µ–Ω–Ω—è –±—É—Ñ–µ—Ä–∞
            self.buffers[buffer_type][key] = []
            
            logger.debug(f"üíæ [FLUSH] {buffer_type}/{symbol}: {len(df)} records")
            
        except Exception as e:
            logger.error(f"‚ùå [FLUSH] {buffer_type}/{symbol}: {e}")
    
    def _flush_all_buffers(self):
        """Flush –≤—Å—ñ—Ö –±—É—Ñ–µ—Ä—ñ–≤"""
        for buffer_type in ['orderbook', 'trades', 'signals']:
            for symbol in settings.pairs.trade_pairs:
                self._flush_buffer(buffer_type, symbol)
    
    async def _rotation_loop(self):
        """–†–æ—Ç–∞—Ü—ñ—è –¥–∞–Ω–∏—Ö (–∫–æ–∂–Ω—ñ 24 –≥–æ–¥)"""
        while True:
            try:
                await asyncio.sleep(86400)  # 24 –≥–æ–¥–∏–Ω–∏
                
                logger.info("üîÑ [ROTATION] Starting data rotation...")
                
                # 1. –í–∏–¥–∞–ª–µ–Ω–Ω—è —Å—Ç–∞—Ä–∏—Ö RAW –¥–∞–Ω–∏—Ö (> 7 –¥–Ω—ñ–≤)
                self._cleanup_raw_data(days=7)
                
                # 2. –ê–≥—Ä–µ–≥–∞—Ü—ñ—è —Å—Ç–∞—Ä–∏—Ö RAW –≤ AGGREGATED (7-30 –¥–Ω—ñ–≤)
                self._aggregate_old_data()
                
                # 3. –ö–æ–º–ø—Ä–µ—Å—ñ—è AGGREGATED –≤ METADATA (30-90 –¥–Ω—ñ–≤)
                self._compress_to_metadata()
                
                # 4. –í–∏–¥–∞–ª–µ–Ω–Ω—è METADATA —Å—Ç–∞—Ä—ñ—à–µ 90 –¥–Ω—ñ–≤
                self._cleanup_metadata(days=90)
                
                # 5. –ü–µ—Ä–µ–≤—ñ—Ä–∫–∞ —Ä–æ–∑–º—ñ—Ä—É
                total_size = self._check_storage_size()
                logger.info(f"üíæ [ROTATION] Total storage: {total_size:.2f} GB")
                
            except Exception as e:
                logger.error(f"‚ùå [ROTATION] Error: {e}")
    
    def _cleanup_raw_data(self, days: int):
        """–í–∏–¥–∞–ª–µ–Ω–Ω—è RAW –¥–∞–Ω–∏—Ö —Å—Ç–∞—Ä—ñ—à–µ N –¥–Ω—ñ–≤"""
        cutoff = datetime.utcnow() - timedelta(days=days)
        
        for date_folder in self.raw_path.iterdir():
            if not date_folder.is_dir():
                continue
            
            try:
                folder_date = datetime.strptime(date_folder.name, "%Y-%m-%d")
                if folder_date < cutoff:
                    # –í–∏–¥–∞–ª—è—î–º–æ –ø–∞–ø–∫—É
                    import shutil
                    shutil.rmtree(date_folder)
                    logger.info(f"üóëÔ∏è [CLEANUP] Removed RAW: {date_folder.name}")
            except Exception as e:
                logger.error(f"‚ùå [CLEANUP] {date_folder}: {e}")
    
    def _aggregate_old_data(self):
        """–ê–≥—Ä–µ–≥–∞—Ü—ñ—è 7+ –¥–Ω—ñ–≤ –¥–∞–Ω–∏—Ö –≤ 1-min bars"""
        # Placeholder - —Ä–µ–∞–ª—ñ–∑–∞—Ü—ñ—è –∞–≥—Ä–µ–≥–∞—Ü—ñ—ó
        pass
    
    def _compress_to_metadata(self):
        """–ö–æ–º–ø—Ä–µ—Å—ñ—è 30+ –¥–Ω—ñ–≤ –≤ metadata"""
        # Placeholder - —Ä–µ–∞–ª—ñ–∑–∞—Ü—ñ—è –∫–æ–º–ø—Ä–µ—Å—ñ—ó
        pass
    
    def _cleanup_metadata(self, days: int):
        """–í–∏–¥–∞–ª–µ–Ω–Ω—è metadata —Å—Ç–∞—Ä—ñ—à–µ 90 –¥–Ω—ñ–≤"""
        cutoff = datetime.utcnow() - timedelta(days=days)
        
        for meta_file in self.meta_path.glob("*.parquet"):
            try:
                # –ü–∞—Ä—Å–∏–º–æ –¥–∞—Ç—É –∑ –Ω–∞–∑–≤–∏ —Ñ–∞–π–ª—É (–Ω–∞–ø—Ä. 2024-10_signals.parquet)
                date_str = meta_file.stem.split('_')[0]
                file_date = datetime.strptime(date_str, "%Y-%m")
                
                if file_date < cutoff:
                    meta_file.unlink()
                    logger.info(f"üóëÔ∏è [CLEANUP] Removed METADATA: {meta_file.name}")
            except Exception as e:
                logger.error(f"‚ùå [CLEANUP] {meta_file}: {e}")
    
    def _check_storage_size(self) -> float:
        """–ü–µ—Ä–µ–≤—ñ—Ä–∫–∞ —Ä–æ–∑–º—ñ—Ä—É —Å—Ö–æ–≤–∏—â–∞ –≤ –ì–ë"""
        total_size = 0
        
        for path in [self.raw_path, self.agg_path, self.meta_path]:
            for file in path.rglob("*"):
                if file.is_file():
                    total_size += file.stat().st_size
        
        return total_size / (1024 ** 3)  # –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü—ñ—è –≤ –ì–ë
    
    async def _on_position_update(self, position):
        """Callback –ø—Ä–∏ –æ–Ω–æ–≤–ª–µ–Ω–Ω—ñ –ø–æ–∑–∏—Ü—ñ—ó"""
        # –ó–±–µ—Ä—ñ–≥–∞—î–º–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∏ —Ç—Ä–µ–π–¥—ñ–≤ –¥–ª—è –∞–Ω–∞–ª—ñ–∑—É
        if position.status == "CLOSED" and position.pnl_confirmed:
            trade_result = {
                'timestamp': position.closed_timestamp,
                'symbol': position.symbol,
                'side': position.side,
                'entry_price': position.entry_price,
                'exit_price': position.avg_exit_price,
                'pnl': position.realised_pnl,
                'close_reason': position.close_reason,
                'lifetime_sec': position.closed_timestamp - position.timestamp,
                'stop_loss': position.stop_loss,
                'take_profit': position.take_profit,
            }
            
            self._add_to_buffer('signals', position.symbol, trade_result)